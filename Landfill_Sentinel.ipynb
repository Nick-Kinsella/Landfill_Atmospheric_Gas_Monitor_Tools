{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a79d32-a388-489a-80fd-c2fd6d92d8af",
   "metadata": {},
   "source": [
    "# Landfill Sentinel\n",
    "\n",
    "## Overview\n",
    "This Jupyter notebook will alow you to..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437fc337-f5cf-42f2-af1e-45e9822a49ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import openeo\n",
    "from shapely.geometry import shape, Point\n",
    "from rasterio import warp\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import Normalize\n",
    "import rasterio\n",
    "from rasterstats import zonal_stats\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa23035e-08c0-48b3-a487-2f37c44391a7",
   "metadata": {},
   "source": [
    "## Connect to OpenEO\n",
    "\n",
    "The code below establishes a connection with the Copernicus openEO platform which provides a wide variety of earth observation datasets\n",
    "\n",
    "- If this does not read as 'Authorised successfully' or 'Authenticated using refresh token', then please ensure that you have completed the setup steps as outlined in section 2.6 of the user guide. \n",
    "\n",
    "- If you have followed the steps in section 2.6 correctly and the problem persists, please look at https://dataspace.copernicus.eu/news for any information about service interruptions. \n",
    "\n",
    "- If there is no news of service problems you can raise a ticket here: https://helpcenter.dataspace.copernicus.eu/hc/en-gb/requests/new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480ef419-3c6b-4ebf-813f-7d61b584b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = openeo.connect(url=\"openeo.dataspace.copernicus.eu\")\n",
    "connection.authenticate_oidc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e50b470-4595-4f13-9af7-3f32702e40e3",
   "metadata": {},
   "source": [
    "## View list of landfills. \n",
    "\n",
    "For easy reference the complete list of landfills can be viewed by running the following piece of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36381e0-f14a-41ec-b925-2a9307cda9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "landfills = gpd.read_file(r\"C:\\GIS_Course\\Landfill_Atmospheric_Gas_Monitor_Tools\\Data\\PZ_landfill_point4326.geojson\")\n",
    "\n",
    "landfills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e9a8d5-1de1-4bb0-a38f-e300af8c3ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_latitude = -34.529350\n",
    "user_longitude = -58.618620\n",
    "buffer_degrees = 0.5\n",
    "\n",
    "site_label = f\"User site ({user_latitude:.2f},{user_longitude:.2f})\"\n",
    "\n",
    "spatial_extent = {\n",
    "    \"west\":  user_longitude - buffer_degrees,\n",
    "    \"south\": user_latitude - buffer_degrees,\n",
    "    \"east\":  user_longitude + buffer_degrees,\n",
    "    \"north\": user_latitude + buffer_degrees,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1bb17d-286f-46ea-8894-0955fe6fbf3e",
   "metadata": {},
   "source": [
    "## Choosing date and gas type\n",
    "\n",
    "This downloads the gas concentration data for a particular date. The two parameters you need to modify before running the code are:\n",
    "\n",
    "- temporal_extent = [\"2023-01-31\", \"2023-03-12\"] (change this to your chosen date range using \"YYYY-MM-DD\" format)\n",
    "- bands=[\"CH4\"], (change this to either one of 'CO', 'HCHO', 'NO2', 'O3', 'SO2', 'CH4')\n",
    "\n",
    "Please note that the temporal extent dates <u>MUST BE IDENTICAL</u> because we are only choosing a single date.\n",
    "\n",
    "If you recieve an error message of 'NoDataAvailable' then please check the list of available data above and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fbe07c-5d0d-4f07-8552-214690c457c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = connection.load_collection(\n",
    "    collection_id=\"SENTINEL_5P_L2\", \n",
    "    temporal_extent = [\"2019-01-01\", \"2020-12-31\"],\n",
    "    spatial_extent=spatial_extent,   # <-- from landfill selection cell\n",
    "    bands=[\"CH4\"],\n",
    ")\n",
    "\n",
    "cube = cube.aggregate_temporal_period(period=\"day\", reducer=\"mean\")\n",
    "cube.download(\"Sentinel-5P_Landfill_daily.nc\", format=\"NetCDF\")\n",
    "print(f\"Downloaded daily Sentinel-5P CH₄ data for {site_label} at {spatial_extent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010364cf-a3c0-4506-8fc2-92a0cb5c129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Annotate NetCDF daily slices with ERA5 wind ===\n",
    "# Input: Sentinel-5P_Landfill_daily.nc (t dimension = daily slices), landfill centroid\n",
    "# Output: winds.csv with [date, wind_speed_mps, wind_from_deg]\n",
    "\n",
    "import os, io, contextlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import cdsapi\n",
    "from tempfile import NamedTemporaryFile\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "in_nc = \"Sentinel-5P_Landfill_daily.nc\"   # downloaded NetCDF\n",
    "lat, lon = user_latitude, user_longitude\n",
    "\n",
    "era5_time = \"13:00\"                        # UTC near S5P overpass\n",
    "out_csv = \"winds.csv\"\n",
    "\n",
    "# open dataset\n",
    "ds = xr.open_dataset(in_nc)\n",
    "da = ds[\"CH4\"]        # CH4 variable\n",
    "times = pd.to_datetime(ds[\"t\"].values)  # 't' is the time dimension\n",
    "ds.close()\n",
    "\n",
    "c = cdsapi.Client()\n",
    "rows = []\n",
    "\n",
    "for dt in tqdm(times, desc=\"Fetching ERA5 winds\", unit=\"day\"):\n",
    "    y, m, d = dt.strftime(\"%Y\"), dt.strftime(\"%m\"), dt.strftime(\"%d\")\n",
    "    with NamedTemporaryFile(suffix=\".nc\") as tmp_file:\n",
    "        # silence cdsapi chatter\n",
    "        with contextlib.redirect_stdout(io.StringIO()):\n",
    "            r = c.retrieve(\n",
    "                \"reanalysis-era5-single-levels\",\n",
    "                {\n",
    "                    \"product_type\": \"reanalysis\",\n",
    "                    \"variable\": [\"10m_u_component_of_wind\",\"10m_v_component_of_wind\"],\n",
    "                    \"year\": y, \"month\": m, \"day\": d,\n",
    "                    \"time\": [era5_time],\n",
    "                    \"format\": \"netcdf\",\n",
    "                    \"area\": [lat + buffer_degrees, lon - buffer_degrees,\n",
    "                             lat - buffer_degrees, lon + buffer_degrees],\n",
    "                },\n",
    "            )\n",
    "            r.download(tmp_file.name)\n",
    "        era = xr.open_dataset(tmp_file.name)\n",
    "        u10 = era[\"u10\"].sel(latitude=lat, longitude=lon, method=\"nearest\").values.item()\n",
    "        v10 = era[\"v10\"].sel(latitude=lat, longitude=lon, method=\"nearest\").values.item()\n",
    "        era.close()\n",
    "\n",
    "    wind_speed = float(np.hypot(u10, v10))\n",
    "    wind_from_deg = float((np.degrees(np.arctan2(-u10, -v10)) + 360.0) % 360.0)\n",
    "\n",
    "    rows.append({\n",
    "        \"date\": dt.date().isoformat(),\n",
    "        \"wind_speed_mps\": wind_speed,\n",
    "        \"wind_from_deg\": wind_from_deg,\n",
    "    })\n",
    "\n",
    "pd.DataFrame(rows).sort_values(\"date\").to_csv(out_csv, index=False)\n",
    "print(f\"Wrote {len(rows)} rows to {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d70286b-238e-46aa-8cca-99e8da38fab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Wind-rotated oversampling to 0.01° (downwind -> NORTH) ===\n",
    "# Inputs:\n",
    "#   - Sentinel-5P_Landfill_daily.nc    (var=CH4, time dim = 't', coords x/y)\n",
    "#   - winds.csv  (columns: date, wind_speed_mps, wind_from_deg)\n",
    "# Output:\n",
    "#   - wrpm_oversampled_0p01deg.tif  (lat/lon EPSG:4326, 0.01° grid)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "# ---- params ----\n",
    "in_nc    = \"Sentinel-5P_Landfill_daily.nc\"\n",
    "winds_csv = \"winds.csv\"\n",
    "src_lon, src_lat = user_longitude, user_latitude\n",
    "box_deg = 0.5     # ~1° x 1° box centered on landfill (paper scale)\n",
    "step    = 0.01    # oversampling grid resolution in degrees (paper)\n",
    "out_tif = \"wrpm_oversampled_0p01deg.tif\"\n",
    "# ----------------\n",
    "\n",
    "west, east  = src_lon - box_deg, src_lon + box_deg\n",
    "south, north = src_lat - box_deg, src_lat + box_deg\n",
    "nx = int(np.round((east - west) / step))\n",
    "ny = int(np.round((north - south) / step))\n",
    "dst_transform = from_origin(west, north, step, step)\n",
    "dst_crs = rasterio.crs.CRS.from_epsg(4326)\n",
    "\n",
    "# open dataset\n",
    "ds = xr.open_dataset(in_nc)\n",
    "da = ds[\"CH4\"]\n",
    "lat = da.coords[\"y\"]\n",
    "lon = da.coords[\"x\"]\n",
    "times = pd.to_datetime(ds[\"t\"].values)\n",
    "\n",
    "# native pixel half-sizes in degrees (approx footprint)\n",
    "dy = float(abs(lat[1] - lat[0])) if lat.size > 1 else 0.1\n",
    "dx = float(abs(lon[1] - lon[0])) if lon.size > 1 else 0.1\n",
    "hy = 0.5 * dy\n",
    "hx = 0.5 * dx\n",
    "\n",
    "# load winds\n",
    "winds = pd.read_csv(winds_csv, parse_dates=[\"date\"])\n",
    "winds[\"date\"] = winds[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# accumulators\n",
    "sum_grid   = np.zeros((ny, nx), dtype=np.float64)\n",
    "count_grid = np.zeros((ny, nx), dtype=np.float64)\n",
    "\n",
    "def rotate_about_source(lon_arr, lat_arr, src_lon, src_lat, angle_deg):\n",
    "    \"\"\"\n",
    "    Rotate small-area coordinates around (src_lon, src_lat) so that 'angle_deg' aligns to NORTH.\n",
    "    Positive angle rotates counter-clockwise.\n",
    "    \"\"\"\n",
    "    km_per_deg_lat = 111.32\n",
    "    km_per_deg_lon = 111.32 * np.cos(np.deg2rad(src_lat))\n",
    "    x = (lon_arr - src_lon) * km_per_deg_lon\n",
    "    y = (lat_arr - src_lat) * km_per_deg_lat\n",
    "    theta = np.deg2rad(angle_deg)\n",
    "    ct, st = np.cos(theta), np.sin(theta)\n",
    "    xr =  x * ct - y * st\n",
    "    yr =  x * st + y * ct\n",
    "    lon_r = xr / km_per_deg_lon + src_lon\n",
    "    lat_r = yr / km_per_deg_lat + src_lat\n",
    "    return lon_r, lat_r\n",
    "\n",
    "# loop days\n",
    "for t in times:\n",
    "    date = t.date().isoformat()\n",
    "    # extract slice (as array) and subset to speed up\n",
    "    s = da.sel(t=t)\n",
    "    # ensure we slice with correct y ordering\n",
    "    if float(lat[0]) > float(lat[-1]):\n",
    "        s = s.sel({lat.name: slice(north, south), lon.name: slice(west, east)})\n",
    "    else:\n",
    "        s = s.sel({lat.name: slice(south, north), lon.name: slice(west, east)})\n",
    "    if s.size == 0:\n",
    "        continue\n",
    "\n",
    "    LON, LAT = np.meshgrid(s[lon.name].values, s[lat.name].values)\n",
    "    ARR = np.array(s.values, dtype=np.float32)\n",
    "\n",
    "    # wind for this date\n",
    "    wrow = winds[winds[\"date\"] == date]\n",
    "    if wrow.empty:\n",
    "        continue\n",
    "    wind_from = float(wrow.iloc[0][\"wind_from_deg\"])\n",
    "    downwind  = (wind_from + 180.0) % 360.0\n",
    "\n",
    "    # rotate so downwind points NORTH (paper)\n",
    "    LONr, LATr = rotate_about_source(LON, LAT, src_lon, src_lat, angle_deg=downwind)\n",
    "\n",
    "    # only keep pixels landing inside the 0.01° canvas; must be finite\n",
    "    inside = (LONr >= west) & (LONr <= east) & (LATr >= south) & (LATr <= north) & np.isfinite(ARR)\n",
    "    if not np.any(inside):\n",
    "        continue\n",
    "    lon_c = LONr[inside]; lat_c = LATr[inside]; vals = ARR[inside].astype(np.float64)\n",
    "\n",
    "    # oversample with rectangular footprint (uniform within dx x dy)\n",
    "    # half-footprint in oversampling index units\n",
    "    hx_idx = max(1, int(np.ceil(hx / step)))\n",
    "    hy_idx = max(1, int(np.ceil(hy / step)))\n",
    "\n",
    "    # map centres to grid indices\n",
    "    j0 = np.floor((lon_c - west) / step).astype(int)      # 0..nx-1 (east)\n",
    "    i0 = np.floor((north - lat_c) / step).astype(int)     # 0..ny-1 (southward)\n",
    "\n",
    "    for ii, jj, v in zip(i0, j0, vals):\n",
    "        i_min = max(0, ii - hy_idx); i_max = min(ny - 1, ii + hy_idx)\n",
    "        j_min = max(0, jj - hx_idx); j_max = min(nx - 1, jj + hx_idx)\n",
    "        sum_grid[i_min:i_max+1, j_min:j_max+1]   += v\n",
    "        count_grid[i_min:i_max+1, j_min:j_max+1] += 1.0\n",
    "\n",
    "# mean composite\n",
    "with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n",
    "    comp = (sum_grid / count_grid).astype(np.float32)\n",
    "\n",
    "profile = {\n",
    "    \"driver\": \"GTiff\",\n",
    "    \"height\": ny, \"width\": nx, \"count\": 1, \"dtype\": \"float32\",\n",
    "    \"crs\": dst_crs, \"transform\": dst_transform,\n",
    "    \"compress\": \"LZW\", \"tiled\": True, \"nodata\": np.nan,\n",
    "}\n",
    "with rasterio.open(out_tif, \"w\", **profile) as dst:\n",
    "    dst.write(comp, 1)\n",
    "    dst.update_tags(method=\"WRPM\", grid=\"0.01deg\", rotate=\"downwind→north\", oversample=\"rectangular footprint\",\n",
    "                    bbox=str((west, south, east, north)), step_deg=step)\n",
    "\n",
    "print(f\"Wrote {out_tif}  ({ny} x {nx} at {step}°)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae113c9-75df-4167-8912-e6c08cb664a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "p = \"wrpm_oversampled_0p01deg.tif\"\n",
    "with rasterio.open(p) as src:\n",
    "    arr = src.read(1)\n",
    "    transform = src.transform\n",
    "    west, north = transform.c, transform.f\n",
    "    step = transform.a\n",
    "    east  = west + step*src.width\n",
    "    south = north - step*src.height\n",
    "\n",
    "print(\"Shape:\", arr.shape, \"| pixel step (deg):\", step)\n",
    "print(\"Extent (W,S,E,N):\", (west, south, east, north))\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(arr, origin=\"upper\", extent=[west, east, south, north])\n",
    "plt.colorbar(label=\"CH₄ enhancement (units of input)\")\n",
    "plt.title(\"WRPM composite (downwind = north)\")\n",
    "plt.xlabel(\"Longitude\"); plt.ylabel(\"Latitude\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab8bf77-4994-4988-a3fc-3f718b5cd0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Oversampling to 0.01° WITHOUT rotation (comparison) ===\n",
    "# Inputs:\n",
    "#   - Sentinel-5P_Landfill_daily.nc    (var=CH4, time dim='t', coords x/y)\n",
    "# Output:\n",
    "#   - oversampled_unrotated_0p01deg.tif  (EPSG:4326, 0.01° grid)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "# ---- params (match your rotated run) ----\n",
    "in_nc   = \"Sentinel-5P_Landfill_daily.nc\"\n",
    "src_lon, src_lat = user_longitude, user_latitude\n",
    "box_deg = 0.5      # ~1° x 1° box\n",
    "step    = 0.01     # oversampling grid resolution in degrees\n",
    "out_tif = \"oversampled_unrotated_0p01deg.tif\"\n",
    "# ----------------------------------------\n",
    "\n",
    "west, east  = src_lon - box_deg, src_lon + box_deg\n",
    "south, north = src_lat - box_deg, src_lat + box_deg\n",
    "nx = int(np.round((east - west) / step))\n",
    "ny = int(np.round((north - south) / step))\n",
    "dst_transform = from_origin(west, north, step, step)\n",
    "dst_crs = rasterio.crs.CRS.from_epsg(4326)\n",
    "\n",
    "# open dataset\n",
    "ds = xr.open_dataset(in_nc)\n",
    "da = ds[\"CH4\"]\n",
    "lat = da.coords[\"y\"]; lon = da.coords[\"x\"]\n",
    "times = pd.to_datetime(ds[\"t\"].values)\n",
    "\n",
    "# native pixel half-sizes in degrees (approx footprint)\n",
    "dy = float(abs(lat[1] - lat[0])) if lat.size > 1 else 0.1\n",
    "dx = float(abs(lon[1] - lon[0])) if lon.size > 1 else 0.1\n",
    "hy = 0.5 * dy\n",
    "hx = 0.5 * dx\n",
    "hy_idx = max(1, int(np.ceil(hy / step)))\n",
    "hx_idx = max(1, int(np.ceil(hx / step)))\n",
    "\n",
    "# accumulators\n",
    "sum_grid   = np.zeros((ny, nx), dtype=np.float64)\n",
    "count_grid = np.zeros((ny, nx), dtype=np.float64)\n",
    "\n",
    "# loop days: subset → oversample (footprint block) → accumulate\n",
    "for t in times:\n",
    "    s = da.sel(t=t)\n",
    "    # subset to analysis box (respect y ordering)\n",
    "    if float(lat[0]) > float(lat[-1]):\n",
    "        s = s.sel({lat.name: slice(north, south), lon.name: slice(west, east)})\n",
    "    else:\n",
    "        s = s.sel({lat.name: slice(south, north), lon.name: slice(west, east)})\n",
    "    if s.size == 0:\n",
    "        continue\n",
    "\n",
    "    LON, LAT = np.meshgrid(s[lon.name].values, s[lat.name].values)\n",
    "    ARR = np.array(s.values, dtype=np.float32)\n",
    "\n",
    "    # take all finite pixels; footprint clipping will limit to canvas\n",
    "    valid = np.isfinite(ARR)\n",
    "    if not np.any(valid):\n",
    "        continue\n",
    "\n",
    "    lon_c = LON[valid]; lat_c = LAT[valid]; vals = ARR[valid].astype(np.float64)\n",
    "\n",
    "    # centre indices on the 0.01° grid (no rotation)\n",
    "    j0 = np.floor((lon_c - west) / step).astype(int)   # 0..nx-1 (east)\n",
    "    i0 = np.floor((north - lat_c) / step).astype(int)  # 0..ny-1 (southward)\n",
    "\n",
    "    # rectangular footprint \"splat\"\n",
    "    for ii, jj, v in zip(i0, j0, vals):\n",
    "        i_min = max(0, ii - hy_idx); i_max = min(ny - 1, ii + hy_idx)\n",
    "        j_min = max(0, jj - hx_idx); j_max = min(nx - 1, jj + hx_idx)\n",
    "        if i_min > i_max or j_min > j_max:\n",
    "            continue\n",
    "        sum_grid[i_min:i_max+1, j_min:j_max+1]   += v\n",
    "        count_grid[i_min:i_max+1, j_min:j_max+1] += 1.0\n",
    "\n",
    "# mean composite\n",
    "with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n",
    "    comp = (sum_grid / count_grid).astype(np.float32)\n",
    "\n",
    "profile = {\n",
    "    \"driver\": \"GTiff\",\n",
    "    \"height\": ny, \"width\": nx, \"count\": 1, \"dtype\": \"float32\",\n",
    "    \"crs\": dst_crs, \"transform\": dst_transform,\n",
    "    \"compress\": \"LZW\", \"tiled\": True, \"nodata\": np.nan,\n",
    "}\n",
    "with rasterio.open(out_tif, \"w\", **profile) as dst:\n",
    "    dst.write(comp, 1)\n",
    "    dst.update_tags(method=\"oversample_no_rotation\", grid=\"0.01deg\",\n",
    "                    bbox=str((west, south, east, north)), step_deg=step)\n",
    "\n",
    "print(f\"Wrote {out_tif}  ({ny} x {nx} at {step}°)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f526b3-0c24-49e9-b1e6-764dfbbd8032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- WRPM rotation sanity check (should report ~0°) ---\n",
    "\n",
    "# use local conversion factors at the landfill\n",
    "km_per_deg_lat = 111.32\n",
    "km_per_deg_lon = 111.32 * np.cos(np.deg2rad(src_lat))\n",
    "\n",
    "# build a unit downwind vector (east = sin α, north = cos α)\n",
    "alpha = np.deg2rad(downwind)\n",
    "x_loc = np.sin(alpha)   # east component\n",
    "y_loc = np.cos(alpha)   # north component\n",
    "\n",
    "# step 1 km along downwind, convert to lon/lat\n",
    "eps_km = 1.0\n",
    "dlon = (eps_km * x_loc) / km_per_deg_lon\n",
    "dlat = (eps_km * y_loc) / km_per_deg_lat\n",
    "test_lon = src_lon + dlon\n",
    "test_lat = src_lat + dlat\n",
    "\n",
    "# rotate coords so that downwind → north\n",
    "tlon, tlat = rotate_about_source(test_lon, test_lat, src_lon, src_lat, angle_deg=downwind)\n",
    "\n",
    "# compute bearing after rotation (0° = north)\n",
    "dx = (tlon - src_lon) * km_per_deg_lon   # east offset in km\n",
    "dy = (tlat - src_lat) * km_per_deg_lat   # north offset in km\n",
    "bearing_after = (np.degrees(np.arctan2(dx, dy)) + 360) % 360\n",
    "\n",
    "print(f\"[WRPM check] Downwind={downwind:.1f}° → after rotation ≈ {bearing_after:.1f}° (expect ~0°)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0526129a-cbd1-49d5-b76a-4aad40c1289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Rotation-centre choice (scan) + final WRPM build ===\n",
    "# Inputs:  Sentinel-5P_Landfill_daily.nc (CH4, time='t', coords x/y)\n",
    "#          winds.csv (date, wind_from_deg, wind_speed_mps)\n",
    "# Uses:    chosen (GeoDataFrame row) for initial landfill guess\n",
    "# Output:  best_centre.json (lon/lat), wrpm_oversampled_0p01deg_best.tif\n",
    "\n",
    "import json, itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# ---------- params ----------\n",
    "in_nc     = \"Sentinel-5P_Landfill_daily.nc\"\n",
    "winds_csv = \"winds.csv\"\n",
    "\n",
    "# initial guess (landfill point)\n",
    "base_lon, base_lat = user_longitude, user_latitude\n",
    "\n",
    "# scan grid settings (degrees): e.g., +/-0.10° around landfill, step 0.02°  →  11 x 11 = 121 centres\n",
    "scan_half_deg = 0.10\n",
    "scan_step_deg = 0.02\n",
    "\n",
    "# fast scoring corridor in the wind-aligned frame (kilometres)\n",
    "score_x_max_km  = 60.0     # along-wind from the source\n",
    "score_y_half_km = 10.0     # ± cross-wind band about the centreline\n",
    "\n",
    "# final WRPM oversampling grid (paper-style)\n",
    "box_deg = 0.5          # ~1° box around the chosen centre\n",
    "step    = 0.01         # oversampling resolution (degrees)\n",
    "out_tif = \"wrpm_oversampled_0p01deg_best.tif\"\n",
    "# ---------------------------\n",
    "\n",
    "# helper: rotate points about (lon0,lat0) by +angle_deg (counter-clockwise), small-area approx\n",
    "def rotate_about_source(lon_arr, lat_arr, lon0, lat0, angle_deg):\n",
    "    km_per_deg_lat = 111.32\n",
    "    km_per_deg_lon = 111.32 * np.cos(np.deg2rad(lat0))\n",
    "    x = (lon_arr - lon0) * km_per_deg_lon  # east km\n",
    "    y = (lat_arr - lat0) * km_per_deg_lat  # north km\n",
    "    th = np.deg2rad(angle_deg)\n",
    "    ct, st = np.cos(th), np.sin(th)\n",
    "    xr =  x * ct - y * st\n",
    "    yr =  x * st + y * ct\n",
    "    lon_r = xr / km_per_deg_lon + lon0\n",
    "    lat_r = yr / km_per_deg_lat + lat0\n",
    "    return lon_r, lat_r\n",
    "\n",
    "# open data & winds\n",
    "ds = xr.open_dataset(in_nc)\n",
    "da = ds[\"CH4\"]\n",
    "lat = da.coords[\"y\"]\n",
    "lon = da.coords[\"x\"]\n",
    "times = pd.to_datetime(ds[\"t\"].values)\n",
    "winds = pd.read_csv(winds_csv, parse_dates=[\"date\"])\n",
    "winds[\"date\"] = winds[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# native pixel footprint (deg) for oversampling\n",
    "dy = float(abs(lat[1] - lat[0])) if lat.size > 1 else 0.1\n",
    "dx = float(abs(lon[1] - lon[0])) if lon.size > 1 else 0.1\n",
    "hy = 0.5 * dy; hx = 0.5 * dx\n",
    "\n",
    "# subset bounds for speed (use base box for all centres; generous to cover the scan)\n",
    "west0, east0  = base_lon - (box_deg + scan_half_deg), base_lon + (box_deg + scan_half_deg)\n",
    "south0, north0 = base_lat - (box_deg + scan_half_deg), base_lat + (box_deg + scan_half_deg)\n",
    "\n",
    "# pre-extract the slices once (to avoid reopening per candidate)\n",
    "slices = []\n",
    "for t in times:\n",
    "    s = da.sel(t=t)\n",
    "    # respect y ordering\n",
    "    s = (s.sel({lat.name: slice(north0, south0), lon.name: slice(west0, east0)})\n",
    "         if float(lat[0]) > float(lat[-1]) else\n",
    "         s.sel({lat.name: slice(south0, north0), lon.name: slice(west0, east0)}))\n",
    "    if s.size == 0:\n",
    "        slices.append(None); continue\n",
    "    LON, LAT = np.meshgrid(s[lon.name].values, s[lat.name].values)\n",
    "    ARR = np.array(s.values, dtype=np.float32)\n",
    "    date = pd.to_datetime(t).date().isoformat()\n",
    "    wrow = winds[winds[\"date\"] == date]\n",
    "    if wrow.empty:\n",
    "        slices.append(None); continue\n",
    "    wind_from = float(wrow.iloc[0][\"wind_from_deg\"])\n",
    "    downwind  = (wind_from + 180.0) % 360.0\n",
    "    slices.append((LON, LAT, ARR, downwind))\n",
    "\n",
    "# ---------- Stage A: scan centres & score ----------\n",
    "lon_offsets = np.arange(-scan_half_deg, scan_half_deg + 1e-9, scan_step_deg)\n",
    "lat_offsets = np.arange(-scan_half_deg, scan_half_deg + 1e-9, scan_step_deg)\n",
    "\n",
    "def score_for_centre(c_lon, c_lat):\n",
    "    # local km/deg for corridor\n",
    "    km_per_deg_lat = 111.32\n",
    "    km_per_deg_lon = 111.32 * np.cos(np.deg2rad(c_lat))\n",
    "    # corridor in degrees for quick clipping (very loose)\n",
    "    y_half_deg = score_y_half_km / km_per_deg_lat\n",
    "    x_max_deg  = score_x_max_km  / km_per_deg_lon\n",
    "\n",
    "    total = 0.0\n",
    "    count = 0.0\n",
    "    for item in slices:\n",
    "        if item is None:\n",
    "            continue\n",
    "        LON, LAT, ARR, downwind = item\n",
    "        # rotate so downwind points NORTH using THIS centre\n",
    "        LONr, LATr = rotate_about_source(LON, LAT, c_lon, c_lat, angle_deg=downwind)\n",
    "        # quick finite + footprint-aware valid mask\n",
    "        valid = np.isfinite(ARR)\n",
    "        if not np.any(valid):\n",
    "            continue\n",
    "        # compute local-plane coords (km) relative to the centre AFTER rotation\n",
    "        xkm = (LONr - c_lon) * km_per_deg_lon\n",
    "        ykm = (LATr - c_lat) * km_per_deg_lat\n",
    "        # select corridor: 0 <= x' <= Xmax and |y'| <= Yhalf\n",
    "        mask = valid & (xkm >= 0.0) & (xkm <= score_x_max_km) & (np.abs(ykm) <= score_y_half_km)\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        vals = ARR[mask].astype(np.float64)\n",
    "        total += float(np.nansum(vals))\n",
    "        count += float(mask.sum())\n",
    "    # score: mean value in corridor; fall back to -inf if no coverage\n",
    "    return (total / count) if count > 0 else -np.inf, count\n",
    "\n",
    "best = {\"lon\": base_lon, \"lat\": base_lat, \"score\": -np.inf, \"count\": 0.0}\n",
    "for dlat, dlon in tqdm(list(itertools.product(lat_offsets, lon_offsets)), desc=\"Scanning centres\"):\n",
    "    c_lon = base_lon + dlon\n",
    "    c_lat = base_lat + dlat\n",
    "    sc, cnt = score_for_centre(c_lon, c_lat)\n",
    "    if sc > best[\"score\"]:\n",
    "        best = {\"lon\": c_lon, \"lat\": c_lat, \"score\": sc, \"count\": cnt}\n",
    "\n",
    "print(\"Best centre:\", best)\n",
    "\n",
    "with open(\"best_centre.json\", \"w\") as f:\n",
    "    json.dump(best, f, indent=2)\n",
    "\n",
    "# ---------- Stage B: build final WRPM composite at best centre ----------\n",
    "src_lon, src_lat = best[\"lon\"], best[\"lat\"]\n",
    "\n",
    "west, east  = src_lon - box_deg, src_lon + box_deg\n",
    "south, north = src_lat - box_deg, src_lat + box_deg\n",
    "nx = int(np.round((east - west) / step))\n",
    "ny = int(np.round((north - south) / step))\n",
    "dst_transform = from_origin(west, north, step, step)\n",
    "dst_crs = rasterio.crs.CRS.from_epsg(4326)\n",
    "\n",
    "sum_grid   = np.zeros((ny, nx), dtype=np.float64)\n",
    "count_grid = np.zeros((ny, nx), dtype=np.float64)\n",
    "\n",
    "# half-footprint in target index units\n",
    "hx_idx = max(1, int(np.ceil((0.5 * dx) / step)))\n",
    "hy_idx = max(1, int(np.ceil((0.5 * dy) / step)))\n",
    "\n",
    "for item in tqdm(slices, desc=\"Building final WRPM\", unit=\"day\"):\n",
    "    if item is None:\n",
    "        continue\n",
    "    LON, LAT, ARR, downwind = item\n",
    "\n",
    "    # rotate so downwind points NORTH about the *best* centre\n",
    "    LONr, LATr = rotate_about_source(LON, LAT, src_lon, src_lat, angle_deg=downwind)\n",
    "\n",
    "    # take all finite pixels; footprint clipping will restrict to canvas\n",
    "    valid = np.isfinite(ARR)\n",
    "    if not np.any(valid):\n",
    "        continue\n",
    "\n",
    "    lon_c = LONr[valid]; lat_c = LATr[valid]; vals = ARR[valid].astype(np.float64)\n",
    "\n",
    "    # map centres to 0.01° grid\n",
    "    j0 = np.floor((lon_c - west) / step).astype(int)     # 0..nx-1 (east)\n",
    "    i0 = np.floor((north - lat_c) / step).astype(int)    # 0..ny-1 (southward)\n",
    "\n",
    "    # rectangular footprint \"splat\" (uniform over dx×dy)\n",
    "    for ii, jj, v in zip(i0, j0, vals):\n",
    "        i_min = max(0, ii - hy_idx); i_max = min(ny - 1, ii + hy_idx)\n",
    "        j_min = max(0, jj - hx_idx); j_max = min(nx - 1, jj + hx_idx)\n",
    "        if i_min > i_max or j_min > j_max:\n",
    "            continue\n",
    "        sum_grid[i_min:i_max+1, j_min:j_max+1]   += v\n",
    "        count_grid[i_min:i_max+1, j_min:j_max+1] += 1.0\n",
    "\n",
    "with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n",
    "    comp = (sum_grid / count_grid).astype(np.float32)\n",
    "\n",
    "profile = {\n",
    "    \"driver\": \"GTiff\",\n",
    "    \"height\": ny, \"width\": nx, \"count\": 1, \"dtype\": \"float32\",\n",
    "    \"crs\": dst_crs, \"transform\": dst_transform,\n",
    "    \"compress\": \"LZW\", \"tiled\": True, \"nodata\": np.nan,\n",
    "}\n",
    "out_path = out_tif\n",
    "with rasterio.open(out_path, \"w\", **profile) as dst:\n",
    "    dst.write(comp, 1)\n",
    "    dst.update_tags(method=\"WRPM\", grid=\"0.01deg\", rotate=\"downwind→north\",\n",
    "                    oversample=\"rectangular footprint\", centre=json.dumps(best),\n",
    "                    bbox=str((west, south, east, north)), step_deg=step)\n",
    "\n",
    "print(f\"Wrote {out_path} at best centre {best['lat']:.5f}, {best['lon']:.5f}; score={best['score']:.3g}, n={int(best['count'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3685a87-422d-4efa-8928-17fe6809cc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "lat0, lon0 = user_latitude, user_longitude\n",
    "import json\n",
    "with open(\"best_centre.json\") as f:\n",
    "    bc = json.load(f)\n",
    "lat1, lon1 = bc[\"lat\"], bc[\"lon\"]\n",
    "\n",
    "\n",
    "km_per_deg_lat = 111.32\n",
    "km_per_deg_lon = 111.32 * np.cos(np.deg2rad((lat0+lat1)/2))\n",
    "\n",
    "dy_km = (lat1 - lat0) * km_per_deg_lat           # +north, -south\n",
    "dx_km = (lon1 - lon0) * km_per_deg_lon           # +east,  -west\n",
    "dist_km = float(np.hypot(dx_km, dy_km))\n",
    "bearing = (np.degrees(np.arctan2(dx_km, dy_km)) + 360) % 360  # 0°=N, clockwise\n",
    "\n",
    "print(f\"Offset ≈ {dist_km:.1f} km, bearing {bearing:.0f}° (from landfill to best centre)\")\n",
    "print(f\"Components: {dy_km:+.1f} km north/south, {dx_km:+.1f} km east/west\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64991b3-0aaf-4fcb-a165-5c6c1ecc33ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Upwind–Downwind Attribution Test (self-contained) ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- inputs ----\n",
    "in_nc = \"Sentinel-5P_Landfill_daily.nc\"   # daily NetCDF (var=CH4, time='t', coords x/y)\n",
    "winds_csv = \"winds.csv\"                    # has columns: date, wind_from_deg, wind_speed_mps\n",
    "src_lon, src_lat = user_longitude, user_latitude\n",
    "box_deg = 0.6                              # subset around source for speed\n",
    "# downwind/upwind boxes in rotated (x=east km, y=north km) frame:\n",
    "along_km = 20.0\n",
    "cross_km = 10.0\n",
    "min_pixels_per_day = 1\n",
    "n_perm = 1000\n",
    "# ----------------\n",
    "\n",
    "# helper: rotate lon/lat about (lon0,lat0) by +angle_deg (CCW), small-area approx\n",
    "def rotate_about_source(lon_arr, lat_arr, lon0, lat0, angle_deg):\n",
    "    km_per_deg_lat = 111.32\n",
    "    km_per_deg_lon = 111.32 * np.cos(np.deg2rad(lat0))\n",
    "    x = (lon_arr - lon0) * km_per_deg_lon  # east km\n",
    "    y = (lat_arr - lat0) * km_per_deg_lat  # north km\n",
    "    th = np.deg2rad(angle_deg)\n",
    "    ct, st = np.cos(th), np.sin(th)\n",
    "    xr =  x * ct - y * st\n",
    "    yr =  x * st + y * ct\n",
    "    lon_r = xr / km_per_deg_lon + lon0\n",
    "    lat_r = yr / km_per_deg_lat + lat0\n",
    "    return lon_r, lat_r\n",
    "\n",
    "# load data & winds\n",
    "ds = xr.open_dataset(in_nc)\n",
    "da = ds[\"CH4\"]\n",
    "lat = da.coords[\"y\"]; lon = da.coords[\"x\"]\n",
    "times = pd.to_datetime(ds[\"t\"].values)\n",
    "\n",
    "wdf = pd.read_csv(winds_csv, parse_dates=[\"date\"])\n",
    "wdf[\"date\"] = wdf[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "wind_map = dict(zip(wdf[\"date\"], wdf[\"wind_from_deg\"]))\n",
    "\n",
    "contrasts = []\n",
    "for t in times:\n",
    "    date = t.date().isoformat()\n",
    "    if date not in wind_map:\n",
    "        continue\n",
    "    wind_from = float(wind_map[date])\n",
    "    downwind  = (wind_from + 180.0) % 360.0\n",
    "\n",
    "    # subset around source (respect y ordering)\n",
    "    s = da.sel(t=t)\n",
    "    if float(lat[0]) > float(lat[-1]):\n",
    "        s = s.sel({lat.name: slice(src_lat+box_deg, src_lat-box_deg),\n",
    "                   lon.name: slice(src_lon-box_deg, src_lon+box_deg)})\n",
    "    else:\n",
    "        s = s.sel({lat.name: slice(src_lat-box_deg, src_lat+box_deg),\n",
    "                   lon.name: slice(src_lon-box_deg, src_lon+box_deg)})\n",
    "    if s.size == 0:\n",
    "        continue\n",
    "\n",
    "    # arrays\n",
    "    LON, LAT = np.meshgrid(s[lon.name].values, s[lat.name].values)\n",
    "    ARR = np.array(s.values, dtype=np.float32)\n",
    "\n",
    "    # rotate so downwind points NORTH (use +downwind)\n",
    "    LONr, LATr = rotate_about_source(LON, LAT, src_lon, src_lat, angle_deg=downwind)\n",
    "\n",
    "    # local-plane coords (km)\n",
    "    km_per_deg_lat = 111.32\n",
    "    km_per_deg_lon = 111.32 * np.cos(np.deg2rad(src_lat))\n",
    "    Xkm = (LONr - src_lon) * km_per_deg_lon\n",
    "    Ykm = (LATr - src_lat) * km_per_deg_lat\n",
    "\n",
    "    valid = np.isfinite(ARR)\n",
    "    dw_mask = valid & (Ykm >= 0.0) & (Ykm <= along_km) & (np.abs(Xkm) <= cross_km)\n",
    "    uw_mask = valid & (Ykm <= 0.0) & (Ykm >= -along_km) & (np.abs(Xkm) <= cross_km)\n",
    "\n",
    "    if dw_mask.sum() < min_pixels_per_day or uw_mask.sum() < min_pixels_per_day:\n",
    "        continue\n",
    "\n",
    "    contrasts.append(float(np.nanmean(ARR[dw_mask]) - np.nanmean(ARR[uw_mask])))\n",
    "\n",
    "ds.close()\n",
    "\n",
    "contrasts = np.array(contrasts, dtype=float)\n",
    "if contrasts.size == 0:\n",
    "    raise RuntimeError(\"No valid days satisfied the masks; try increasing box_deg or lowering min_pixels_per_day.\")\n",
    "\n",
    "effect = float(np.nanmean(contrasts))\n",
    "stderr = float(np.nanstd(contrasts, ddof=1) / np.sqrt(len(contrasts)))\n",
    "z = effect / (stderr + 1e-12)\n",
    "\n",
    "# permutation (sign-flip null)\n",
    "rng = np.random.default_rng(42)\n",
    "perm_effects = np.array([np.mean(contrasts * rng.choice([-1,1], size=len(contrasts))) for _ in range(n_perm)])\n",
    "p = float((np.sum(np.abs(perm_effects) >= abs(effect)) + 1) / (n_perm + 1))\n",
    "\n",
    "print(f\"Days used: {len(contrasts)}\")\n",
    "print(f\"Downwind–Upwind mean diff = {effect:.2f}, SE={stderr:.2f}, z={z:.2f}, p≈{p:.3f}\")\n",
    "\n",
    "# plots\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(contrasts, bins=20, edgecolor=\"k\")\n",
    "plt.axvline(0, color=\"k\", linestyle=\"--\")\n",
    "plt.axvline(effect, color=\"red\", linestyle=\"-\", label=f\"Mean={effect:.1f}\")\n",
    "plt.title(\"Histogram of daily contrasts (downwind–upwind)\")\n",
    "plt.xlabel(\"CH4 difference\"); plt.ylabel(\"Days\"); plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(contrasts, vert=True, labels=[\"Contrasts\"])\n",
    "plt.axhline(0, color=\"k\", linestyle=\"--\")\n",
    "plt.title(\"Boxplot of daily contrasts\")\n",
    "plt.ylabel(\"CH4 difference\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa72061-e1ae-4b72-8cfc-132233d2f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Wind-shuffled null plot for attribution test ===\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# contrasts from previous cell (array of daily diffs)\n",
    "# effect, perm_effects already computed\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.hist(perm_effects, bins=30, color=\"lightblue\", edgecolor=\"k\", alpha=0.7, density=True)\n",
    "plt.axvline(effect, color=\"red\", linestyle=\"--\", linewidth=2, label=f\"Observed mean = {effect:.2f}\")\n",
    "plt.axvline(-effect, color=\"grey\", linestyle=\":\", linewidth=1)\n",
    "\n",
    "plt.title(\"Permutation test: downwind–upwind contrast\")\n",
    "plt.xlabel(\"Mean contrast (CH4 units)\")\n",
    "plt.ylabel(\"Relative frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc38178-517e-4632-9f17-b9f4c3cb628a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
